# ğŸ’¬ Dialogue Insights

This is a self-contained NLP-powered web app that analyzes conversation transcripts for sentiment and filler-word usage. Built using Hugging Face Transformers, spaCy, and Streamlit. The app extracts per-turn and overall conversation insights such as sentiment, filler word usage, and speaker statistics, and presents them in an engaging dashboard.

---

## ğŸš€ Features

1. ğŸ“Š Sentiment analysis per dialogue turn (Positive, Negative, Neutral)
2. ğŸ—£ï¸ Filler word ratio (e.g., "um", "like", "uhh")
3. ğŸ“ˆ Interactive web dashboard using Streamlit
4. ğŸ“„ Custom transcript support (12â€“16 line dialogues)
5. âš ï¸ Defensive error handling for invalid or missing input
6. ğŸ” Sentiment analysis using CardiffNLP RoBERTa (3-class)
7. ğŸ—£ï¸ Filler word analysis using spaCy (customizable filler list in config)

---

## ğŸ“Š Metrics & Visualizations in the Dashboard
The application analyzes the conversation transcript and presents the following metrics in the Streamlit dashboard:

### ğŸ–¥ï¸ UI Components

#### ğŸ“¤ Sidebar
- Upload `.txt` file containing the transcript.

#### ğŸ  Landing Summary
- ğŸ‘¥ **Speakers Detected**
- ğŸ“„ **Total Turns**
- ğŸ’¬ **Average Filler Ratio**
- ğŸ“Š **Average Sentiment Polarity**

#### ğŸ“‹ Annotated Transcript
- Full parsed dialogue with computed metrics per turn.

##### ğŸ”½ Per-Turn Metrics (Expandable)
- Sentiment Trend (line chart)
- Filler Ratio (bar chart)
- Colored Sentiment Line (speaker overlay)

#### ğŸ”½ Overall Metrics (Expandable)
- Speaker Summary Table
- Sentiment Distribution (Pie)
- Word Cloud
- Top 5 Filler Words (Bar/Table toggle)

## Folder Structure
.
â”œâ”€â”€ app/                         # Core NLP logic
â”‚   â”œâ”€â”€ analyzer.py              # Sentiment & filler ratio computations
â”‚   â”œâ”€â”€ metrics.py               # Summary & per-turn metric calculations
â”‚   â””â”€â”€ parser.py                # Parses raw transcript string
â”‚
â”œâ”€â”€ config/                      # YAML config files
â”‚   â””â”€â”€ pipeline_config.yaml     # Filler word list, top filler count, etc.
â”‚
â”œâ”€â”€ data/                        # Transcript input/output storage
â”‚   â””â”€â”€ temp_transcript.txt      # Temporary file for uploaded transcript
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â”œâ”€â”€ test_parser.py
â”‚   â”œâ”€â”€ test_analyzer.py
â”‚   â””â”€â”€ test_metrics.py
â”‚
â”œâ”€â”€ ui/                          # Streamlit dashboard
â”‚   â”œâ”€â”€ dashboard.py             # Main Streamlit entry logic
â”‚   â”œâ”€â”€ components.py            # Shared styles (card CSS)
â”‚   â””â”€â”€ sections/                # Modular UI views
â”‚       â”œâ”€â”€ landing_summary.py
â”‚       â”œâ”€â”€ annotated_transcript.py
â”‚       â”œâ”€â”€ per_turn_metrics.py
â”‚       â””â”€â”€ overall_metrics.py
â”‚
â”œâ”€â”€ utils/                       # Helper functions
â”‚   â””â”€â”€ common_functions.py      # YAML loader and shared utilities
â”‚
â”œâ”€â”€ app.py                       # ğŸ” ENTRY POINT for Streamlit app
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.py                     # Project metadata (optional packaging)
â””â”€â”€ README.md                    # You are here




## âš™ï¸ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/your-username/talkwise-ai.git
cd talkwise-ai
```
### 2. Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```
### 3. Install the dependencies
```bash
pip install -r requirements.txt
```
### 4. Run Unit Tests (Optional)
```bash
pytest tests/
```
### 5. Run the Application
```bash
streamlit run app.py
```